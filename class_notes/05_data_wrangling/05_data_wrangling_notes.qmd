---
title: "Bio 724: Data wrangling class notes"
author: "Paul Magwene"
date: "2024-09-25"
date-format: iso
format: 
  html:
    embed-resources: true
---


In the real world you'll often create a data set (or be given one) in a format that is less than ideal for analysis.  This can happen for a number of reasons. For example, the data may have been recorded in a manner convenient for collection and visual inspection, but which does not work well for analysis and plotting.  Or the data may be an amalgamation of multiple experiments, in which each of the experimenters used slightly different naming conventions. Or the data may have been produced by an instrument that produces output with a fixed format.  Sometimes important experimental information is included in the column headers of a spreadsheet.

Whatever the case, we often find ourselves in the situation where we need to "wrangle" our data into a "tidy" format before we can proceed with visualization and analysis. The "R for Data Science" text discusses some desirable rules for "tidy" data in order to facilitate downstream analyses. These are:

  1. Each variable must have its own column.
  1. Each observation must have its own row.
  1. Each value must have its own cell.

In this lecture we're going to walk through an extended example of wrangling some data into a "tidy" format.

## Libraries


```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(patchwork)
```


## Data

To illustrate a data wrangling pipeline, we're going to use a gene expression microarray data set, based on the following paper:

* Spellman PT, et al. 1998. Comprehensive identification of cell cycle-regulated genes of the yeast Saccharomyces cerevisiae by microarray hybridization. Mol Biol Cell 9(12): 3273-97.

In this paper, Spellman and colleagues tried to identify all the genes in the yeast genome (>6000 genes) that exhibited oscillatory behaviors suggestive of cell cycle regulation.  To do so, they combined gene expression measurements from six different types of cell cycle synchronization experiments.

The six types of cell cycle synchronization experiments included in this data set are:

1. synchronization by alpha-factor = "alpha"
2. synchronization by cdc15 temperature sensitive mutants = "cdc15"
3. synchronization by cdc28 temperature sensitive mutants = "cdc28"
4. synchronization by elutration = "elu"
5. synchronization by cln3 mutatant strains = "cln3"
6. synchronization by clb2 mutant strains = "clb2"

## Loading the data

*Download the Spellman data to your filesystem* from [this link](https://github.com/Bio724D/Bio724D_2024_2025/raw/refs/heads/main/data/spellman-1998-expression.tsv) (right-click the "Download" button and save to your Downloads folder or similar).  

I suggest that once you download the data, you open it in a spreadsheet program (e.g. Excel) or use the RStudio Data Viewer to get a sense of what the data looks like.

Let's load it into R, using the `read_tsv()` function, using the appropriate file path. 

```{r, message=FALSE}
# the file path may differ on your computer
spellman <- read_tsv("~/Downloads/spellman-1998-expression.tsv")
```

The initial dimensions of the data frame are:

```{r}
dim(spellman)
```


## Check your data!

It's a good habit when working with any new data set to check your data after import to make sure it got read as expected.

* The `View()` function provides a spreadsheet like graphical view of the data: `View(spellman)`

* The `names()` function will show you the column names assigned to the data frame: `names(spellman)`

* The `dplyr::glimpse()` function will provide a summary view of each column, showing you the type assigned to each column and the first few values in each.


## Renaming data frame columms 


If you look at the Spellman data set in your spreadsheet program you might have noticed that the first column of data did not have a name in the header.  This is a problem during import because in a R data frame, every column must have a name.  To resolve this issues, the `read_tsv()` function (and other functions in the `readr` pckage) assigned "dummy names" in cases where none was found.  There was a single missing name corresponding to the first column, which was given the dummy name `...1`.

Our first task is to give the first column a more meaningful name.  This column gives "systematic gene names" -- a standardized naming scheme for genes in the yeast genome.  We'll use `dplyr::rename()` to rename `...1` to `gene`.  Note that `rename` can take multiple arguments if you need to rename multiple columns simultaneously.

```{r}
spellman_clean <- 
  spellman |>
  rename(gene = "...1")
```



## Dropping unneeded columns

Take a look at the Spellman data again in your spreadsheet program (or using `View()`).  You'll notice there are some blank columns.  For example there is a column with the header "alpha" that has no entries.  These are simply visual organizing elements that the creator of the spreadsheet added to separate the different experiments that are included in the data set. 

We can use `dplyr::select()` to drop columns by prepending column names with the negative sign:

```{r}
# drop the alpha column keeping all others
spellman_clean <-
  spellman_clean |>
  select(-alpha)  
```

Note that usually `select()`  keeps only the variables you specify.  However if the first expression is negative, `select` will instead automatically keep all variables, dropping only those you specify. 

### Finding all empty columns

In the example above, we looked at the data and saw that the "alpha" column was empty, and thus dropped it.  This worked  because there are only a modest number of columns in the data frame in its initial form.  However, if our data frame contained thousands of columns, this "look and see" procedure would be inefficient.  Can we come up with a general solution for removing empty columns from a data frame?

When you load a data frame from a spreadsheet, empty cells are given the value `NA`.  I'm going to illustrate two ways to work with `NA` values to remove empty columns from our data frame.  


#### Solution using colSums() and standard indexing

In previous class sessions we were introduced to the function `is.na()` which tests each value in a vector or data frame for whether it's NA or not.  We can count NA values in a vector by summing the output of `is.na()`. Conversely we can count the number of "not NA" items by using the negation operator (`!`):

```{r}
# count number of NA values in the alpha0 column
sum(is.na(spellman_clean$alpha0))

# count number of values that are NOT NA in alpha0
sum(!is.na(spellman_clean$alpha0))
```

This seems like it should get us close to a solution but `sum(is.na(..))` when applied to a data frame counts NAs across the entire data frame, not column-by-column.

```{r}
# doesn't do what we hoped!
sum(is.na(spellman_clean))
```


If we want sums of NAs by column, we can use the `colSums()` function instead of `sum()` as illustrated below:

```{r}
# get number of NAs by column
colSums(is.na(spellman_clean))
```

Columns with *all* missing values can be more conveniently found by asking for those columns where the number of "not missing" values is zero:

```{r}
# get number of NAs by column
colSums(!is.na(spellman_clean))
```

To get the corresponding names of the columns where all values are missing we can do the following:

```{r}
# get names of all columns for which all rows are NA
# using standard indexing
names(spellman_clean)[colSums(!is.na(spellman_clean)) == 0]
```

The solution to removing all empty columns thus becomes:

```{r}
empty_columns <- names(spellman_clean)[colSums(!is.na(spellman_clean)) == 0]

spellman_clean |>
  # The minus sign before any_of() indicates negation
  # So read this as "drop any of these columns"
  select(-any_of(empty_columns)) |>
  names()
```
#### Solution using the `where()` helper function

An alternate approach is to use the `where()` helper function that works with `dplyr::select()`.  

To use `where()` we need to define a predicate function which returns a Boolean (logical) value depending on whether a vector is "all NA". Here is a simple implementation such a function based on the use of the built-in `all()` function.

```{r}
all.na <- function(x) {
  all(is.na(x))
}
```

Having defined `all.na()` above we can now use this with `select()` and `where()` as follows:

```{r}
spellman_clean <-
  spellman_clean |>
  select(-where(all.na))
  
dim(spellman_clean) # note number of columns has been reduced
```

Version 4.1 of R introduced a new shorthand syntax of "anonymous functions"  (sometimes called "lambda expressions" in other programming languages), so we could have defined our predicate function "inline" as so:

```{r}
spellman_clean |>
  select(-where(\(x) all(is.na(x))))  |>
  names()
```


Tidyverse packages support an [alternate syntax for writing anonymous functions](https://adv-r.hadley.nz/functionals.html#purrr-shortcuts), as shown below:


```{r}
# Yet another way to write the anonymous function
spellman_clean |>
  select(-where( ~ all(is.na(.x))))  |>
  names()
```


### Dropping columns by matching names

Only two time points from the cln3 and clb2 experiments were reported in the original publication. The column names associated with these experiments are of the form "cln3-1", "cln3-2", "cln2-1", etc. Since complete time series are unavailable for these two experimental conditions we will drop them from further consideration.  

`select()` can be called be called with a number of "helper functions" ([Selection language](https://tidyselect.r-lib.org/reference/language.html)). Here we'll illustrate the `matches()` helper function which matches column names to a "regular expression".  Regular expressions (also referred to as "regex" or "regexp") are a way of specifying patterns in strings. We'll cover regular expressions in a later lecture. For the purposes of this document we'll illustrate  regexs by example; for a more detailed explanation of regular expressions see the the regex help(`?regex`) and the [Chapter on Strings in "R for Data Analysis"](http://r4ds.had.co.nz/strings.html): 

Let's see how to drop all the "cln3" and "clb2" columns from the data frame using `matches()`:

```{r}
spellman_clean <-
  spellman_clean |> 
  select(-matches("cln3")) |>
  select(-matches("clb2"))
```

If we wanted we could have collapsed our two match statements into one as follows:

```{r}
spellman_clean <-
  spellman_clean |>
  select(-matches("cln3|clb2"))
```

In this second example, the character "|" is specifing an OR match within the regular expression, so this regular expression matches column names that contain "cln3" OR "clb2".


## Reshaping data with tidyr

The `tidyr` package provides functions for reshaping or tidying data frames.  `tidyr` is yet another component of the tidyverse, and thus was loaded by the `library(tidyverse)`. 

We're going to look at two functions `tidyr::pivot_longer()` and `tidyr::extract()`, and how they can be combined with now familiar `dplyr` functions we've seen previously.  The reading assignment for today's class session covers a variety of other functions defined in `tidyr`.
 
The Spellman data, as I provided it to you, is in what we would call "wide" format.  Each column (besides the `gene` column) corresponds to an experimental condition *and* time point.  For example, "alpha0" is the alpha-factor experiment at time point 0 mins; "alpha7" is the alpha-factor experiment at time point 7 mins, etc.  The cells within each column correspond to the expression of a corresponding gene (given by the first column which we renamed `gene`) in that particular experiment at that particular time point.

In every expression column, the cells represents the same abstract property of interest -- the expression of a gene of interest in a particular experiment/time point.  Our first task will be to rearrange our "wide" data frame that consists of many different columns representing gene expression into a "long" data frame with just a single column representing expression.  We'll also create a new column to keep track of  which experiment and time point the measurement came from.

### Wide to long conversions using `pivot_longer()`

NOTE: `tidyr::pivot_longer()` and `tidyr::pivot_wider()` replace the "superseded" tidyr functions, `tidyr::gather()` and `tidyr::spread()` that work similarly. I recommend you read the [tidyr vignette on pivoting](https://tidyr.tidyverse.org/articles/pivot.html).

To use `pivot_longer()` you need to specify: 1) the columns your are collapsing; 2) the name of a new column that will hold the names of the columns collapsed; and 3) the name of a new column  will hold the values of the collapsed columns. 

Here we want to collapse all 73 of the expression columns -- "alpha0" to "elu390" -- into two columns: 1) a column to represent the expt/time point of the measurement, and 2) a column to represent the corresponding expression value.  The column we don't want to touch are the `gene`, `std.name`, and `description`.

```{r}
spellman_long <-
  spellman_clean |>
  pivot_longer(cols = !gene,
               names_to = "expt.and.time",
               values_to = "expression")
```

Take a moment to look at the data in the "long format":

```{r}
head(spellman_long)
```

And compare the dimensions of the wide data to the new data:

```{r}
dim(spellman_clean)  # for comparison
dim(spellman_long)
```

As you see, we've gone from a data frame with `r nrow(spellman_clean)` rows and `r ncol(spellman_clean)` columns (wide format), to a new data frame with `r nrow(spellman_long)` rows and `r ncol(spellman_long)` columns (long format). 

### Extracting information from combined variables using `separate_wider_regex`

The column `expt.and.time` violates one of our principles of tidy data: "Each variable must have its own column."  This column conflates two different types of information -- the experiment type and the time point of the measurement.  Our next task is to split this information up into two new variables, which will help to facilitate downstream plotting and analysis.

One complicating factor is that the different experiments/time combinations have different naming conventions:

  * The "alpha" and "elu" experiments are of the form "alpha0", "alpha7", "elu0", "elu30", etc.  In this case, the first part of the string gives the experiment type (either alpha or elu) and the following digits give the time point. 

  * In the "cdc15" and "cdc28" experiments the convention is slightly different; they are of the form "cdc15_0", "cdc15_10", "cdc28_0", "cdc28_10", etc.  Here the part of the string before the underscore gives the experiment type, and the digits after the underscore give the time point.
  
Because of the differences in naming conventions, we will find it easiest to break up `spellman_long` into a series of sub-data sets corresponding to each experiment type in order to extract out the experiment and time information.  After processing each data subset separately, we will join the modified sub-data frames back together.

###  Subsetting rows 

Let's start by getting just the rows corresponding to the "alpha" experiment/times. Here we use `dplyr::filter` in combination with `stringr::str_detect` to get all those rows in which the `expt.and.time` variable contains the string "alpha". We can't use `matches` here, because that is a `select` helper function and doesn't work with `filter`.


```{r}
alpha.long <- 
  spellman_long |>
  filter(str_detect(expt.and.time, "alpha"))

# look at the new data frame
dim(alpha.long)
head(alpha.long, n = 10)
```

### Splitting columns

Having subsetted the data, we can now split `expt.and.time` into two new variables -- `expt` and `time`.  To do this we use `tidyr::separate_wider_regex` function to do regular expression matching and splitting.

```{r}
alpha.long <-
  alpha.long |>
  separate_wider_regex(
    cols = expt.and.time,  # column we're extracting from
    patterns=c(expt = "alpha", time = "[[:digit:]]+"))  |>
  mutate(time = as.integer(time))  # convert new time column to integer
```




Let's take a moment to look at the `patterns` argument to `separate_wider_regex`.  This argument specifies the column names and corresponding regular expression used to extract the column data.  In this case we are going to extract two columns, `expt` and `time`.  The `expt` regex is a simple matching, it simply says find and extra the string `alpha`. The `time` regex reads `[[:digit:]]+`. `[[:digit:]]` indicates we're looking for a numeric digit.  The `+` after `[[:digit:]]` indicates that we want to match  *one or more* digits (i.e. to get a match we need to find at least one digit, but more than one digit should also be a match).


Let's take a look at the new version of `alpha.long` following application of `separate_wider_regex`:

```{r}
glimpse(alpha.long)
```


A data frame for the elutriation ("elu") data can be created similarly:

```{r}
elu.long <-
  spellman_long |>
  filter(str_detect(expt.and.time, "elu")) |>
  separate_wider_regex(
    cols = expt.and.time,  
    patterns=c(expt="elu", time="[[:digit:]]+"))  |>
  mutate(time = as.integer(time))  
```


#### A fancier regex for the cdc experiments

Now let's process the cdc experiments (cdc15 and cdc28).  As before we extract the corresponding rows of the data frame using `filter` and `str_detect`.  However, here we can use a simpler function `separate_wider_delim` because the experiment type is consistently separated from the time field by an underscore:


```{r}
cdc.long <- 
  spellman_long |>
  # both cdc15 and cdc28 contain "cdc" as a sub-string
  filter(str_detect(expt.and.time, "cdc")) |>
  separate_wider_delim(
    cols = expt.and.time,  
    delim = "_",
    names = c("expt", "time"))  |>
  mutate(time = as.integer(time))  
```



### Combining data frames

If you have two or more data frames with identical columns, the rows of the data frames can be combined into a single data frame using `dplyr::bind_rows` .  For example, to reassemble the `alpha.long`, `elu.long`, and `cdc.long` data frames into a single data frame we do:

```{r}
spellman.final <- bind_rows(alpha.long, elu.long, cdc.long)

# check the dimensions of the new data frame
dim(spellman.final)
```

### Sorting data frame rows

Currently the `spellman.final` data frame is sorted by time point and experiment.  

```{r}
head(spellman.final, n = 10)
```

It might be useful instead to sort by gene and experiment.  To do this we can use `dplyr::arrange`:

```{r}
spellman.final <-
  spellman.final |>
  arrange(gene, expt)

# look again at the rearranged data
head(spellman.final, n = 10)
```

## Using your tidy data

Whew -- that was a fair amount of work to tidy our data!  But having done so we can now carry out a wide variety of very powerful analyses.  

### Visualizing gene expression time series

Let's start by walking through a series of visualizations of gene expression time series.  Each plot will show the expression of one or more genes, at different time points, in one or more experimental conditions. Our initial visualizations exploit the "long" versions of the tidy data.

First a single gene in a single experimental condition:

```{r}
spellman.final |>
  filter(expt == "alpha", gene == "YAL022C") |>
  ggplot(aes(x = time, y = expression)) + 
    geom_line() + 
    labs(x = "Time (mins)", y = "Expression of YAL022C")
```

We can easily modify the above code block to visualize the expression of multiple genes of interest:

```{r}
genes.of.interest <- c("YAL022C", "YAR018C", "YGR188C")

spellman.final |>
  filter(gene %in% genes.of.interest, expt == "alpha") |>
  ggplot(aes(x = time, y = expression, color = gene)) +
    geom_line() + 
    labs(x = "Time (mins)", y = "Normalized expression",
         title = "Expression of multiple genes\nfollowing synchronization by alpha factor")
```

By employing `facet_wrap()` we can visualize the relationship between this set of genes in each of the experiment types:

```{r}
spellman.final |>
  filter(gene %in% genes.of.interest) |>
  ggplot(aes(x = time, y = expression, color = gene)) +
    geom_line() + 
    facet_wrap(~ expt) +
    labs(x = "Time (mins)", y = "Normalized expression",
         title = "Expression of Multiple Genes\nAcross experiments") 
```

The different experimental treatments were carried out for varying lengths of time due to the differences in their physiological effects. Plotting them all on the same time scale can obscure that patterns of oscillation we might be interested in, so let's modify our code block so that plots that share the same y-axis, but have differently scaled x-axes.

```{r}
spellman.final |>
  filter(gene %in% genes.of.interest) |>
  ggplot(aes(x = time, y = expression, color = gene)) +
    geom_line() + 
    facet_wrap(~ expt, scales = "free_x") +
    labs(x = "Time (mins)", y = "Normalized expression",
         title = "Expression of Multiple Genes\nAcross experiments") 
```


### Finding the most variable genes

When dealing with vary large data sets, one ad hoc filtering criteria that is often employed is to focus on those variables that exhibit that greatest variation.  To do this, we first need to order our variables (genes) by their variance.  Let's see how we can accomplish this using our long data frame:

```{r}
by.variance <-
  spellman.final |>
  group_by(gene) |> 
  summarize(expression.var = var(expression, na.rm = TRUE)) |>
  arrange(desc(expression.var))

head(by.variance)
```

The code above calculates the variance of each gene but ignores the fact that we have different experimental conditions.  To take into account the experimental design of the data at hand, let's calculate the average variance across the experimental conditions:

```{r}
by.avg.variance <-
  spellman.final |>
  group_by(gene, expt) |>
  summarize(expression.var = var(expression, na.rm = TRUE)) |>
  group_by(gene) |>
  summarize(avg.expression.var = mean(expression.var)) 

head(by.avg.variance)
```

Based on the average experession variance across experimental conditions, let's get the names of the 1000 most variable genes:

```{r}
top.genes.1k <- 
  by.avg.variance |>
  slice_max(avg.expression.var, n = 1000) |>
  pull(gene)

head(top.genes.1k)
```

For simplicities sake we will restrict our attention to the cdc28 experiment, and only consider the 1000 most variables genes with no more than one missing observation in this experimental condition.

```{r}
cdc28 <-
  spellman.final |>
  filter(expt == "cdc28") |>
  group_by(gene) |>
  filter(sum(is.na(expression)) <= 1) |>
  ungroup()   # removes grouping information from data frame

top1k.genes <-
  cdc28 |>
  group_by(gene) |>
  summarize(expression.var = var(expression, na.rm = TRUE)) |>
  slice_max(expression.var, n = 1000) |>
  pull(gene)
    
top1k.cdc28 <- 
  cdc28 |>
  filter(gene %in% top1k.genes)
```





## Long-to-wide conversion using `pivot_wider()`

Our long data frame consists of four variables -- `gene`, `expt`, `time`, and `expression`.  This made it easy to create visualizations and summaries where time and expression were the primaries variables of interest, and gene and experiment type were categories we could condition on.

To facilitate analyses that emphasize comparison between genes, we want to create a new data frame in which each gene is itself treated as a variable of interest along with time, and experiment type remains a categorical variable.  In this new data frame rather than just four columns in our data frame, we'll have several thousand columns -- one for each gene.

To accomplish this reshaping of data, we'll use the function `tidyr::pivot_wider()`.  `tidyr::pivot_wider()` is the inverse of `tidyr::pivot_longer()`.  `pivot_longer()` took multiple columns and collapsed them together into a smaller number of new columns.  By contrast, `pivot_wider()` creates new columns by spreading values from single columns into multiple columns.

Here let's use `pivot_wider` to spread the gene name and expression value columns to create a new data frame where the genes are the primary variables (columns) of the data. 

```{r}
spellman.wide <-
  spellman.final |>
  pivot_wider(names_from = gene, values_from = expression)
```

Now let's examine the dimensions of this wide version of the data:

```{r}
dim(spellman.wide)
```

And here's a visual view of the first few rows and columns of the wide data:

```{r}
spellman.wide[1:5, 1:8]
```

From this view we infer that the rows of the data set represent the various combination of experimental condition and time points, and the  columns represents the 6178 genes in the data set plus the two columns for `expt` and `time`.


## Exploring bivariate relationships using "wide" data

The "long" version of our data frame proved useful for exploring how gene expression changed over time.  By contrast, our "wide" data frame is more convenient for exploring how pairs of genes covary together.  For example, we can generate bivariate scatter plots depicting the relationship between two genes of interest:

```{r}
two.gene.plot <-
  spellman.wide |>
  filter(!is.na(YAR018C) & !is.na(YAL022C)) |>  # remove NAs
  ggplot(aes(x = YAR018C, y = YAL022C)) +
    geom_point() + 
    theme(aspect.ratio = 1)

two.gene.plot
```

From the scatter plot we infer that the two genes are "positively correlated" with each other, meaning that high values of one tend to be associated with high values of the other (and the same for low values).

We can easily extend this visualization to facet the plot based on the experimental conditions:

```{r}
two.gene.plot + facet_wrap(~expt, nrow = 2, ncol = 2) 
```

Correlation is a standard measure the degree of association between pairs of continuous variables. Briefly, correlation is a measure of linear association between a pair of variables, and ranges from -1 to 1. A value near zero indicates the variables are uncorrelated (no linear association), while values approaching +1 indicate a strong positive association (the variables tend to get bigger or smaller together) while values near -1 indicate strong negative association (when one variable is larger, the other tends to be small).  

Let's calculate the correlation between YAR018C and YAL022C:

```{r}
spellman.wide |>
  filter(!is.na(YAR018C) & !is.na(YAL022C)) |>
  summarize(cor = cor(YAR018C, YAL022C))
```

The value of the correlation coefficient for YAR018C and YAL022C, ~0.69, indicates a fairly strong association between the two genes.

As we did for our visualization, we can also calculate the correlation coefficients for the two genes under each experimental condition:

```{r}
spellman.wide %>%
  filter(!is.na(YAR018C) & !is.na(YAL022C)) |>  
  group_by(expt) |>
  summarize(cor = cor(YAR018C, YAL022C))
```

This table suggests that the the strength of correlation between YAR018C and YAL022C may depend on the experimental conditions, with the highest correlations evident in the cdc28 and elu experiments.

### Large scale patterns of correlations

Now we'll move from considering the correlation between two specific genes to looking at the correlation between many pairs of genes.  As we did in the previous section, we'll focus specifically on the 1000 most variable genes in the cdc28 experiment.

First we filter our wide data set to only consider the cdc28 experiment and those genes in the top 1000 most variable genes in cdc28:

```{r}
top1k.cdc28.wide <- 
  top1k.cdc28 |>
  pivot_wider(names_from = gene, values_from = expression)
```

With this restricted data set, we can then calculate the correlations between every pair of genes as follows:

```{r}
cdc28.correlations <- 
  top1k.cdc28.wide |>
  select(-expt, -time)  |> # drop expt and time
  cor(use = "pairwise.complete.obs")
```

The argument `use = "pairwise.complete.obs"` tells the correlation function that for each pair of genes to use only the pariwse where there is a value for both genes (i.e. neither one can be NA).  

Given $n$ genes, there are $n \times n$ pairs of correlations, as seen by the dimensions of the correlation matrix.

```{r}
dim(cdc28.correlations)
```

To get the correlations with a gene of interest, we can index with the gene name on the rows of the correlation matrix. For example, to get the correlations between the gene YAR018C and the first 10 genes in the top 1000 set:

```{r}
cdc28.correlations["YAR018C",1:10]  
```

In the next statement we extract the names of the genes that have correlations with YAR018C greater than 0.6.   First we test genes to see if they have a correlation with YAR018C greater than 0.6, which returns a vector of TRUE or FALSE values.  This vector of Boolean values is than used to index into the row names of the correlation matrix, pulling out the gene names where the statement was true.

```{r}
pos.corr.YAR018C <- rownames(cdc28.correlations)[cdc28.correlations["YAR018C",] > 0.6]
length(pos.corr.YAR018C)
```

We then return to our long data to show this set of genes that are strongly positively correlated with YAR018C.  

```{r}
top1k.cdc28 |>
  filter(gene %in% pos.corr.YAR018C) |>
  ggplot(aes(x = time, y = expression, group = gene)) + 
    geom_line(alpha = 0.33) +
    theme(legend.position = "none")
```

As is expected, genes with strong positive correlations with YAR018C show similar temporal patterns with YAR018C. 


We can similarly filter for genes that have negative correlations with YAR018C. 

```{r}
neg.corr.YAR018C <- colnames(cdc28.correlations)[cdc28.correlations["YAR018C",] <= -0.6]
```

As before we generate a line plot showing these genes:

```{r}
top1k.cdc28 |>
  filter(gene %in% neg.corr.YAR018C) |>
  ggplot(aes(x = time, y = expression, group = gene)) +
    geom_line(alpha = 0.33) +
    theme(legend.position = "none")  
```


### Adding new columns and combining filtered data frames

Now let's create a new data frame by: 1) filtering on our list of genes that have strong positive and negative correlations with YAR018C; and 2) creating a new variable, "corr.with.YAR018C", which indicates the sign of the correlation.  We'll use this new variable to group genes when we create the plot.

```{r}
pos.corr.df <- 
  top1k.cdc28 |>
  filter(gene %in% pos.corr.YAR018C) |>
  mutate(corr.with.YAR018C = "positive")

neg.corr.df <- 
  top1k.cdc28 |>
  filter(gene %in% neg.corr.YAR018C) |>
  mutate(corr.with.YAR018C = "negative")

combined.pos.neg <- rbind(pos.corr.df, neg.corr.df)
```

Finally, we plot the data, colored according to the correlation with YAR018C: 

```{r, fig.width = 8, fig.height=4, warning=FALSE}
ggplot(combined.pos.neg, 
       aes(x = time, y = expression,  group = gene,
           color = corr.with.YAR018C)) + 
  geom_line(alpha=0.25) + 
  # changes legend title and values for color scale
  scale_color_manual(name = "Correlation with YAR018C",
                       values = c("blue", "red"))  + 
  labs(title = "Genes strongly positively and negatively correlated with YAR018C",
       x = "Time (mins)", y = "Expression") + 
  facet_wrap(~corr.with.YAR018C, nrow=1)
```


