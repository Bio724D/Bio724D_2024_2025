{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7dd67cd-da7a-4efc-bed4-6e82aaf041d8",
   "metadata": {},
   "source": [
    "# Practice with Pandas\n",
    "\n",
    "Author: Greg Wray  \n",
    "2025-APR-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d228367-48b0-431e-a202-57b0b7dc9398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from datetime import date\n",
    "import pyarrow\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399c804f-8427-47ec-99f3-149852520176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record current Python and library versions for reproducibility\n",
    "print(\"session date\", date.today())\n",
    "print(\"python \", sys.version)\n",
    "print(\"numpy \", np.__version__)\n",
    "print(\"pandas \", pd.__version__)\n",
    "print(\"pyarrow \", pyarrow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b091081f-d07d-423c-b348-13899e88794a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Pandas\n",
    "\n",
    "**Pandas** is a library of data structures and functions for working with **tabular** data in Python. Like NumPy, pandas is widely used in data science, machine learning, and scientific computing. \n",
    "\n",
    "Pandas is designed for *heterogenous* data organized by column (data frame or spreadsheet). This is in contrast to NumPy, which is designed for *homogenous* data in every dimension (vector, matrix, array, and tensor). \n",
    "\n",
    "Pandas provides two primary data structures. A **DataFrame** is desgined to hold tabular data, similar to a data frame or Tibble in R. DataFrames are the central way data is stored and manipulated in pandas. Each column in a DataFrame is the same length and contains values of the same data type. A **Series** is a 1-dimensional, ordered container that is similar to a NumPy ndarray. You can think of a series as a single column of a DataFrame. A Series holds values of a single data type, and will automatically \"up-cast\" data to homogenize data types (e.g., any integers will be converted to floats if there are any float values). \n",
    "\n",
    "Both DataFrame and Series data structures provide an automatic integer index that references rows and items, respectively. This default index can be replaced with a user-defined index based on integers or strings. In addition, DataFrames provide automatic integer column names, although in practice these are typically replaced with string names.  \n",
    "\n",
    "Pandas Series and DataFrames support **vectorized operations** for mathematics, functions, and conditions, similar to ndarrays in NumPy. Refer to the examples below.\n",
    "\n",
    "Pandas provides a large set of functions and methods to facilitate working with DataFrame and Series objects. The performance-critical components of pandas are written in C and Cython. Use the prefix `pd.` to access pandas functions; attributes and methods do not need the prefix since they are appended directly to a pandas data object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3291e135-0560-4585-9f43-e45b09a0a26e",
   "metadata": {},
   "source": [
    "## Data frames from scratch\n",
    "\n",
    "You can create a DataFrame completely by hand using a construtor function, although in practice this is not common. The simplest approach is to pass a nested list to the constructor. Passing a dictionary also works, but be aware that each dictionary is treated as a column (see examples below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c339aee8-a99b-4d85-8547-e923fd2831b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame by hand from a nested list\n",
    "#    note that pandas automatically assigns integer names for rows and columns\n",
    "dataA = [['SPU_000003',4.90,0.18,1.71,0.19,0.43], ['SPU_000007',2.39,0.75,6.17,0.01,0.07],\n",
    "        ['SPU_000008',3.03,0.24,0.74,0.38,0.64], ['SPU_000011',0.47,0.18,0.48,0.48,0.72],\n",
    "        ['SPU_000013',4.36,0.23,3.45,0.06,0.22], ['SPU_000016',0.29,0.37,0.44,0.50,0.74]]\n",
    "dfA = pd.DataFrame(dataA)\n",
    "dfA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f9bcfa-def0-4b94-bba7-9e385fb4b3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame by hand from a dictionary\n",
    "#    note that keys are used as column names by default; rows are assigned integer names\n",
    "dataB = {'SPU_000003' : [4.90,0.18,1.71,0.19,0.43], 'SPU_000007' : [2.39,0.75,6.17,0.01,0.07],\n",
    "        'SPU_000008' : [3.03,0.24,0.74,0.38,0.64], 'SPU_000011' : [0.47,0.18,0.48,0.48,0.72],\n",
    "        'SPU_000013' : [4.36,0.23,3.45,0.06,0.22], 'SPU_000016' : [0.29,0.37,0.44,0.50,0.74]}\n",
    "dfB = pd.DataFrame(dataB)\n",
    "dfB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca6939c-ab19-4d36-98dc-ba5079361f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a better way to create a DataFrame by hand from a dictionary\n",
    "#    use keys as column names\n",
    "dataC = {'gene' : ['SPU_000003','SPU_000007','SPU_000008','SPU_000011','SPU_000013','SPU_000016'], \n",
    "        'time_1' : [4.90, 2.39, 3.03, 0.47, 4.36, 0.29],\n",
    "        'time_2' : [0.18, 0.75, 0.24, 0.18, 0.23, 0.37],\n",
    "        'time_3' : [1.71, 6.17, 0.74, 0.48, 3.45, 0.44],\n",
    "        'time_4' : [0.19, 0.01, 0.38, 0.48, 0.06, 0.50],\n",
    "        'time_5' : [0.43, 0.07, 0.64, 0.72, 0.22, 0.74]}\n",
    "dfC = pd.DataFrame(dataC)\n",
    "dfC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca459ec-546b-4a89-b8a9-cacdbb402f34",
   "metadata": {},
   "source": [
    "## Data import and export\n",
    "\n",
    "In most situations, you will create a DataFrame by importing values from a file. You may also want to export a DataFrame to a standard file format for archival purposes or to share. Pandas provides functions to carry out these tasks. \n",
    "\n",
    "**Importing data.** `read_csv()` is the most common tool for data import. Be sure to prefix with `.pd` to generate a pandas DataFrame. \n",
    "                                                        \n",
    "`read_csv()` can accommodate any separator, in spite of its name.\n",
    "\n",
    "By default, `read_csv()` creates an index column of consecutive integers for each row. If a header row is present in the input file, it will be used for column names; otherwise, columns will be named with consecutive integers. See later sub-sections for how to change these behaviors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0fb20a-d487-422e-b2e7-f30ce593ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a .csv file \n",
    "df = pd.read_csv('countries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c45cd9-d5a3-437d-8b58-cc51be724e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a .tsv file by defining the separator\n",
    "df = pd.read_csv('countries.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4f5056-50b3-4f2e-adce-c7041871de27",
   "metadata": {},
   "source": [
    "**Import a subset of columns.** You can specificy which rows to import using column names if a header row is present. You can specify which columns to import using column position regardless of whether names are available.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c5357e-9340-4771-978a-8f0575bde617",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import a subset of columns by name\n",
    "df = pd.read_csv('countries.csv', usecols=['country_name', 'species_total', 'species_endemic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29fe362-4e03-4d5f-bcf3-360d1ad6bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import a subset of columns by name\n",
    "df = pd.read_csv('countries.csv', usecols=[0, 8, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5a8995-5ccf-46a8-9d5d-a6778cac8622",
   "metadata": {},
   "source": [
    "**Exporting data.** You can export DataFrames to a variety of file formats. While `.csv` is highly portable and perhaps the most appropriate format for sharing data, it is worth considering other options for large data sets. Two common formats are Parquet and Feather, which provide compression and preserve data types. To access these file formats, import the `pyarrow` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc8c621-fee4-44dc-a808-4755ab76fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to .csv\n",
    "df.to_csv('my_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b47953-497e-4efc-b2ac-046f4f59fef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to .tsv by defining the separator\n",
    "df.to_csv('my_file.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791d39fe-b23f-4ad7-8c15-be1032096c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to parquet format\n",
    "df.to_parquet('my_file.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dda98d-88aa-411b-97c9-757410db2eb5",
   "metadata": {},
   "source": [
    "**Managing the index column.** The default behavior of `.to_csv()` is to include both the row and column indexes in the output file. If you then import the data back into a pandas DataFrame, the column names will be incorporated as expected, but a *new* integer index column will be added and the old one will become the first data column. To avoid this, you can either save to `.csv` without the index or import to DataFrame without the old index. You also have the option of exporting and importing without column names and of supplying different column names when importing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65194076-bf50-4a74-8b05-6c4b4e273c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to .csv without the index column\n",
    "df.to_csv('my_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7168789a-dd9f-462f-836a-54254c2a70f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop an unnecessary index column when reading a .csv\n",
    "df = pd.read_csv('my_file.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23d192d-b118-4ac3-814c-bcd0e848b799",
   "metadata": {},
   "source": [
    "**Managing column names.**  By default, `read_csv()` uses names in a header row (if present) for column names in the resulting DataFrame. Similarly, `to_csv()` uses column names in a DataFrame to create a header row in the output file. You can change these behaviors and work around multi-line headers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b60a33e-fd92-4b85-ba5a-08a671279c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import from .csv dropping column names (they will be replaced by integer names)\n",
    "df = pd.read_csv('my_file.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82deeb1f-628a-45e1-b9ef-ee4dee8b3729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import from .csv and use the second header row as column names\n",
    "df = pd.read_csv('my_file.csv', header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dae78d8-2091-41af-8291-88a552494e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import from .csv dropping column names and replace with names that you supply\n",
    "df = pd.read_csv('my_file.csv', header=0, names=['col1', 'col2', 'col3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b60dd4f-10af-426b-b91b-77365dc70da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to .csv without column names\n",
    "df.to_csv('my_file.csv', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86b41d6-1ec8-483b-8721-5d37e9ee6005",
   "metadata": {},
   "source": [
    "**Converting data types.** By default, `read_csv()` will infer data types for each column during import. You can change the data type of individual columns at any time after importing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb12c7c-962e-4c3b-bbfc-fe76f90c27e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the data type of a column\n",
    "df['area_total'] = df['area_total'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae3742f-5e9b-4bab-ac76-c39030452915",
   "metadata": {},
   "source": [
    "## Viewing DataFrame contents\n",
    "Note that the DataFrame includes an index column that is automatically generated when created; it is the left-most column and lacks a column name. By default, Pandas assigns a consecutive positive integer to the index for each row when creating a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2594ff-a9c1-4353-883b-a5cf5e7bbb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the first 5 (or specified number of) rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92353738-2eba-4430-b294-584367328491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the last 5 (or specified number of) rows\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f060651f-a164-4cab-a210-df64dcb80575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of columns to display to 100\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0106fae-25fc-46d6-90cd-b8ea815cf650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view a random sample of rows\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d9852e-bed0-4e92-a187-193d7bf2abb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view a random fraction of rows\n",
    "df.sample(frac=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2738bb-eb12-480c-af8c-d8d83d0822ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the optional state argument for reproducibility when randomly sampling\n",
    "df.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d05397-0d5d-4520-bf35-4f6a70234bb3",
   "metadata": {},
   "source": [
    "## Accessing information about a DataFrame\n",
    "Pandas provides an extensive set of attributes and methods to retrieve information about a DataFrame. Note that calling an attribute requires only the name, while calling a method requires the name followed by `()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f8e820-332a-4d44-bf07-90e411728d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the dimensions of a DataFrame; attribute\n",
    "df.shape   # rows, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f3f90a-4dd3-4fe6-8f0d-335f54034b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve column names; attribute; returns an Index object\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90883520-8755-4c7c-9a10-371310f2d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve a list of column names\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad2f304-5b86-4b07-964b-52a1baa8a3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve a Series of column names and their associated data types; attribute\n",
    "#    iterables, including strings, are described as 'object'\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeea60f-57d7-428b-8ca6-bdd94ae1617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve a list of index values; attribute\n",
    "#   for the default integer index this will be a range-derived object\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a1d325-b0f7-4d32-b74c-f2972d5ddc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a quick view of a data frame; method\n",
    "#   gotcha: there is also an attribute .info that returns a glance of contents\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f27d488-fe51-4e10-8272-45f53f27e9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve basic statistics for numeric columns (ignores non-numeric columns); method\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2050f13e-81b7-4e1f-a07a-1fc1843f959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve basic statistics for Boolean and factor-like columns; method\n",
    "df[['continent_name', 'bioregion_name']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2ba296-01e8-46c9-98c7-cd9dba6955e7",
   "metadata": {},
   "source": [
    "## Indexing a DataFrame\n",
    "Pandas provides several approaches to indexing. The two recommended approaches use index *positions* or *values* with the methods `.iloc[]` and `.loc[]`, respectively. For approaches to index just columns or rows, see subsequent sections.\n",
    "\n",
    "Referencing one or more rows will return a DataFrame; referencing a single column will return a Series while referencing multiple columns will return a DataFrame. To retrieve a single column as a DataFrame, wrap the name or integer in a list of length 1 (compare first two code blocks below). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351b48ba-661d-485b-9032-565ba0f0f021",
   "metadata": {},
   "source": [
    "**Indexing with iloc[ ].** This approach references the *position* of rows and columns rather than the value of their indexes. It is an integer-based approach that uses standard square-bracket, zero-based indexing; it accepts slices, negative values, and steps. \n",
    "\n",
    "Passing a single argument indexes rows; two arguments index rows and columns respectively; `:,` followed by one argument indexes columns. \n",
    "\n",
    "Because indexing with `.iloc[]` uses the position of rows, it will almost always return a different result before and after sorting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a95fd40-9201-40d5-be2c-f49e67458205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve a row as a Series (all values up-cast to string)\n",
    "df.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4f398b-4722-46a3-a140-7000a531b6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to retrieve a row as a DataFrame, pass index value as list\n",
    "df.iloc[[12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094f3711-5919-4d90-b49a-da0c50d100e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to retrieve multiple rows, extend the list\n",
    "df.iloc[[12, 29, 7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e662d0c-099b-435d-b27d-a03fa7075c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve value from a single cell; preserves data type\n",
    "df.iloc[1, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b2b9c1-2753-4e1b-a6cd-0298b7e38d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slices work as expected\n",
    "df.iloc[:5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9977e487-9f07-45e3-a4ff-057168579bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative values also work\n",
    "df.iloc[-5:, -4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3a9f2c-bfb4-4439-bce0-8ade7df19054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve a single column; returns a Series\n",
    "df.iloc[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ec0637-0390-425f-b1f8-4d7caf14b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve a single column as a DataFrame by placing in a list of one\n",
    "df.iloc[:, [5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e7e1c0-6a08-4a28-9811-5b5041ebc581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to retrieve multiple columns, extend the list\n",
    "df.iloc[:, [0, 14, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d0db1b-8d8b-461a-ab32-7d3336b87264",
   "metadata": {},
   "source": [
    "**Indexing with .loc[ ].** This approach references the *values* of indexes rather than the position of rows and columns. By default, Pandas creates an integer index column, which `.loc[]` treats as row names. If no column names are provided when a DataFrame is created, pandas will create a header composed of integer values, which `.loc[]` treats as column names. The best way to think about `.loc[]` indexing is that everything is a name, even if it is an integer.\n",
    "\n",
    "In practice, columns usually have string names. This means that, with the default integer index, `.loc[]` indexing combines numerals for rows with strings for columns. Keep in mind that the numerals are names and not positions.\n",
    "                                                                                                            With `.loc[] indexing, single values and slices (including open slices and strides) are allowed. Slices can be used with both numeral and string names. Negative numbers are not allowed, because they are not names. \n",
    "                \n",
    "It's important to keep in mind that `.loc[]` indexing is not the same as normal square-bracket indexing. There are some similarities: it is zero-based and allows slices. However, there are three key differences: the end value of slices are *included*, negative values are not allowed, and strings can be used as values.  \n",
    "\n",
    "You can pass a list of row and/or column names even if they are integers, because `.loc[]` treats them as values rather than positions. Importantly, this behavior means that indexing with `.loc[]` will return the same result before and after sorting, unlike `.iloc[]`. \n",
    "\n",
    "With `.loc[]` indexing, passing a single argument indexes rows; two arguments index rows and columns respectively; and `:,` followed by one argument indexes columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812e828c-dd09-437a-9c9d-af79ce77a26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve a single row as a Series\n",
    "df.loc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f21633-c37a-4b53-b2eb-1f37660fdd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve a single row as a DataFrame\n",
    "df.loc[[20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0b0c21-8628-4960-90b2-cc460c038b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve multiple rows (including discontinuous) by extending the list\n",
    "df.loc[[4, 20, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bb3959-0ee7-4b94-a869-6634ed65de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve a range of rows; note that the end value of the slice is included\n",
    "df.loc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8287ad-92f2-4052-b659-064f5a47964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using negative values with .loc[] does not work as expected (or throws an error)\n",
    "df.loc[-7:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79cf269-760f-4fef-87b1-4ad833aaf946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve a single column using a string name; returns a Series\n",
    "df.loc[:, 'country_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0d513d-097e-4141-9358-49cad796fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve a range of columns using a slice\n",
    "df.loc[:, 'country_name' : 'bioregion_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53818271-4eaf-456a-82d5-263b1e69fc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve discontinuous columns using a list\n",
    "df.loc[:, ['country_name', 'continent_name', 'species_endemic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215fd439-5e6c-4b12-b117-cd981a8c870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrive a subset of rows and columns\n",
    "df.loc[7:10,['country_name', 'continent_name', 'species_endemic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0675fd75-99d0-4bdb-953c-3f5fb0c39ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve a subset of discontinuous rows and columns using two lists\n",
    "df.loc[[7, 6, 11, 2], ['country_name', 'continent_name', 'species_endemic']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ad5df7-241a-45bb-b2b8-43ef2ff17243",
   "metadata": {},
   "source": [
    "**Setting the index column.** The default integer index column can be replaced by any other column, which will then be used for indexing rows. You can also specify multiple columns to act as the index, although this is not commonly needed.\n",
    "\n",
    "Although you can set any column to be the index, it is most useful when there is a column that can be used for `.loc[]` indexing (see examples below). This can make code more readable, especially for filtering and joins. \n",
    "\n",
    "Pandas allows duplicate values in the index column, but in general an index is most useful when each value is unique. To learn how to check for unique values, \"Summarizing data\", below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b44440-77bc-4619-8a0b-b7219e40c1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the index to a different column\n",
    "df2 = df.set_index('country_name')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e725b20d-3aac-4acd-ae23-baf6e0e1cbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now you can use .loc indexing with more intuitive names for rows and columns\n",
    "df2.loc[['Iceland', 'Japan'], ['continent_name', 'bioregion_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d934d1d1-6ec1-450e-8323-eedc9ffeafd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrive entire rows by name\n",
    "df2.loc[['Iceland', 'Japan'], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0432cd1c-784f-45c6-a20e-9a30bd79bf66",
   "metadata": {},
   "source": [
    "## Filtering columns of a DataFrame\n",
    "\n",
    "**Referencing columns by name.** Columns can indicated by enclosing a single name or list of names in square brackets. \n",
    "\n",
    "Passing a single name returns a Series; passing a list of one  or more names returns a DataFrame. When passing a list, columns can be discontinuous and/or out of order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824dc284-200d-4016-a4e1-a8441731bf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view a single column by name; returns a Series\n",
    "df['country_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646e6478-5f3d-49c5-a523-35dc282cfe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view a single column by name; returns a DataFrame\n",
    "df[['country_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7773aac9-2ca0-4314-9e1e-e26ca3dd4ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view a discontinuous subset of columns\n",
    "df[['country_name','species_total', 'species_resident', 'species_endemic']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc2618f-4fad-4c9d-bb78-e687f91e78c5",
   "metadata": {},
   "source": [
    "Comprehensions can be used to generate lists based on filtering column names. This is particularly useful for large DataFrames where columns are named according to a consistent convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3f6556-eec5-42bf-92d3-d0c0db1407f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter column names by substring using a list comprehension\n",
    "df[[c for c in df.columns if 'species' in c]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2452581-6b6c-4e2b-b773-10b4e34e0f33",
   "metadata": {},
   "source": [
    "Pandas allows you to reference a single column using just its name without square brackets. This approach is *not* recommended and may be deprecated in future releases of pandas. However, you may encounter this approach in older code, so it's useful to know how to recognize it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cdd806-cb52-49c3-807e-d7372d70a996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view a single column using a \"bare\" name; not recommended\n",
    "df.country_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c660df0-5ef4-4753-8482-1dbd11ba7494",
   "metadata": {},
   "source": [
    "**Referencing columns by position.** It is possible to reference columns by position using `.columns[]` with standard numerical square bracket indexing; it accepts slices and negative values but not steps. \n",
    "\n",
    "In general, this method is *not recommended*. Using numbers is more brittle than using names and the code is more difficult to read. If you do want to use position to refer to columns, `.iloc[]` indexing (above) is a better approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73570c05-8d12-481b-9316-fa67de9f5319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrive the names of columns by position\n",
    "df.columns[3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca676e9-00b3-4474-8795-d645bf628424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the values of columns by position\n",
    "df[df.columns[3:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afe09d1-81f3-4f5a-bc61-c111cfca9558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view a numeric slice of columns\n",
    "df[df.columns[-5:]]    # returns last 5 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1247f78f-ca29-4578-8c88-c20586aeb9df",
   "metadata": {},
   "source": [
    "**Referencing columns by data type.** In some cases, it can be useful to retrive values from all columns of a particular data type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414144d0-57d0-4bd7-95ea-f742bfac3385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view all columns of a particular data type\n",
    "df.select_dtypes(int) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a9926d-e166-4e64-af81-e0c8ebb6d3f1",
   "metadata": {},
   "source": [
    "## Filtering rows of a DataFrame\n",
    "\n",
    "Pandas provides several ways to filter rows based on values in one or multiple columns. Any expression that evalutes to `True` or `False` can be used as a condition, including compound conditions. \n",
    "\n",
    "When referring to a column in a condition, precede with the name of the DataFrame and use square brackets with the column name (see examples below). \n",
    "\n",
    "**Filter based on numeric value.** Equality and inequality conditions work as expected. To filter for maximum and minimum values in a column, see \"Summarizing Data\" below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9f7f40-1f57-4851-81fb-bfc54a1f8204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter using a comparison operator\n",
    "df[df['species_endemic'] >= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad34080-4e9a-4e6b-be91-382021558ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter based on result of arithmetic expression involving two columns\n",
    "df[df['species_resident'] / df['species_total'] < 0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5c2fbe-4c5b-471a-8d47-a90ecc7410f9",
   "metadata": {},
   "source": [
    "**Filter based on string value.** Pandas allows you to use regex when filtering (requires importing the standard Python `re` library)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed38c25-067a-472a-b53c-16eff49b2ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for rows containing a specific value in one column \n",
    "df[df['continent_name'] == 'Africa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6e9e62-1081-45dc-ae91-6737f488345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter based on a substring\n",
    "df[df['country_name'].str.contains('New')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2f61ef-f039-4ead-845f-ba2c3d650ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for names ending in 'land' using regex\n",
    "df[df['country_name'].str.contains('land$', regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329b8ea7-fe08-4cb8-8a3e-7c89aa0b0dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for names consisting of two words using regex\n",
    "df[df['country_name'].str.contains('. .', regex=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae997ccb-2b56-4e05-ba22-583bf79af2b4",
   "metadata": {},
   "source": [
    "**Filter based on membership.** First define a comparison list or set, then use `.isin()` to test for membership.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a28a956-29ca-4850-ad0d-1da157dd69b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter based on membership; first define a list to test against\n",
    "western_hemisphere = ['South America', 'North America']\n",
    "df[df['continent_name'].isin(western_hemisphere)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1ae3d9-fc45-4a85-a63e-f6aaa92bbaac",
   "metadata": {},
   "source": [
    "**Filter based on compound condition.** Note that compound conditions use the `&` and `|` operators rather than `and` and `or` keywords. Negate any Boolean expression with `~` and wrapping in round brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e5ac3b-bace-4eb6-b718-4faea255b2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for conditions in two columns \n",
    "df[(df['continent_name'] == 'Africa') & (df['species_endemic'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ade546-fc51-447e-affa-f484eb9efdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for rows where the country is not in Europe\n",
    "df[~(df['continent_name'] == 'Europe')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e7c9cd-6844-4eaf-a75f-1589d7e1a546",
   "metadata": {},
   "source": [
    "**Filtering compound conditions with .query().** Using `.query()` provides a simpler and more readable syntax when writing compound queries. Note that the syntax uses `and` and `or` keywords. To negate all or part of an expression, use the `~` operator.\n",
    "\n",
    "A useful feature of `.query()` is that you can use variables in conditions. Any variable in scope can be referenced by preceding its identifier with `@`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a352add-08de-4bac-97c1-7ab5b49162d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for conditions in two columns; equivalent to query 2 cells above\n",
    "df.query(\"(continent_name == 'Africa') and (species_endemic > 10)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aecb5e-cc68-49ad-9a68-abf1ce77a025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by condition using an external variable\n",
    "threshold = 15\n",
    "df.query('(eba_count > @threshold)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f851e1a0-3cbc-4ac9-a9f8-47296388b222",
   "metadata": {},
   "source": [
    "**Removing duplicates.**  Rows are treated as duplicates if and only if they contain the same value in every column.  \n",
    "\n",
    "Removing duplicates does not alter the original DataFrame; assign to a new identifier to keep the results. The default behavior when removing duplicates is to keep the first occurrence and drop all others, but this can be changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d011464-3b9a-4842-b1d4-ce9a8849b13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a boolean index of duplicated rows\n",
    "duplicates = df.duplicated()\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e290a51d-cee0-4d3e-8f31-2d4b627f0ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of duplicated rows\n",
    "duplicates.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e9e4e4-811a-4ac2-be99-d80b2ef8aca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the first occurrence of duplicated rows and drop all others\n",
    "df2 = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b083dc-7244-4026-982a-ab45358989ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all duplicated rows (i.e., retain no rows that are duplicated)\n",
    "df_deduplicated = df.drop_duplicates(duplicates, keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c56669-4f04-4dcb-be47-9c47e3a2052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Boolean index based on duplicate values in a single column\n",
    "df_deduplicated = df.drop_duplicates(subset['country_name'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e542b399-1b09-4088-9b4f-b3b012dea967",
   "metadata": {},
   "source": [
    "## Updating values\n",
    "\n",
    "Becoming proficient with indexing gives you the ability to update values in precise ways. The examples below are illustrate basic approaches to updating using a condition or by replacement. \n",
    "\n",
    "Most methods for updating values in a DataFrame operate *in place*, so be careful! \n",
    "\n",
    "**Replace values in a column based on a condition.** In the following example, the condition and the updated value refer to the same column, but this is not required. Note the need to specify the column to update explicitly for this reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a661485d-f2e2-4edb-89cb-c8791d8cd512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change all continent_name values matching 'Europe' to 'Europa'\n",
    "df.loc[df['continent_name'] == 'Europe', 'continent_name'] = 'Europa'\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc2a716-0ff7-4a93-8b69-f12e536f77d6",
   "metadata": {},
   "source": [
    "**Replace values in a column from an ordered iterable.**  It is possible to update values in an entire column directly from a base Python list or tuple. The length of the data structure must be the same as the length of columns in the DataFrame. Make sure values are in the correct order (aligned) with rows in the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc2e5e2-63a5-4330-afa5-d5f931b55ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace values in the eba_count with new values (in this case, meaningless)\n",
    "new_values = range(0, 70)\n",
    "df['eba_count'] = new_values\n",
    "df.iloc[0:8, -5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3737c14-a398-4b86-9cc8-5e10384dfaa0",
   "metadata": {},
   "source": [
    "## Summarizing data\n",
    "Pandas offers methods for retrieving the usual set of summary statistics. Queries for single value will return an integer or float; the same statistic applied to multiple columns will return a Series; and multiple statistics applied to multiple columns will return a DataFrame.\n",
    "\n",
    "Pass a list of column names to retrieve values for more than one column. Use the `.agg()` method to apply multiple summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118bbc55-ca93-4f01-9aee-ba48465a9888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the mean value of a column\n",
    "df['species_total'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0d3c16-f3bf-435d-bd1b-daf2bfcf06f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the count of rows containing non-null values for a given column\n",
    "df['biodiv_index'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8f0756-a968-4e89-aae8-b05ffc9b80b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any of these queries can be run on multiple columns at once; returns a Series\n",
    "df[['species_total', 'species_resident', 'species_endemic']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beddab03-6a7b-4837-97e4-3cab3cc5475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run multiple methods on a set of columns, use the .agg() method\n",
    "df[['species_total', 'species_resident', 'species_endemic']].agg(['mean', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01faefab-21e9-407a-b339-0a577561b523",
   "metadata": {},
   "source": [
    "**Unique values.** Pandas provides methods for counting, listing, and tallying unique values by column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e510b1-049d-4f6f-bb39-5ba9cca19a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve unique values from a column; returns an ndarray\n",
    "df['continent_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bda03d-32d3-442f-b072-91be5e8d3058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the count of unique values from a column\n",
    "df['continent_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d535397-ac26-463b-922a-76a67e7980cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the count of each unique value from a column; returns a Series\n",
    "df['continent_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094ac317-1d9b-4487-8623-7c4c8cfbc1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the proportion of each unique value from a column; returns a Series\n",
    "df['continent_name'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9113bc7a-da04-4cba-a29d-391b907e86da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the count of each unique value combination from multiple columns; returns a multi-index Series\n",
    "df[['continent_name','bioregion_name']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8568ff3f-755a-4348-bf50-a40a32e93eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the count of each unique value combination from multiple columns as a DataFrane\n",
    "df[['continent_name','bioregion_name']].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd43f8da-0dc6-4329-90b3-b20390849827",
   "metadata": {},
   "source": [
    "**Grouping.** The `.groupby()` method works similarly to grouping in R. This allows you to apply any of the summary statistics to values in one or more columns after grouping by some other variable. Use the `.agg` method to apply multiple summary statistics; pass a list of column names to retrieve values for more than one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559e4b2c-798f-4faf-81c6-4bb7e71542e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the mean number of species per country from each continent\n",
    "df.groupby('continent_name')[['species_total']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2d82cf-6926-4e34-8abd-cbcf7d2d9286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate multiple summary statistics by categorical variable\n",
    "df.groupby('continent_name')[['species_total']].agg(['mean', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb2b7e4-a6af-4057-b9df-7a15de3eadba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate multiple summary statistics by categorical variable\n",
    "df.groupby('continent_name')[['species_total', 'species_endemic']].agg(['mean', 'min', 'max'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "444817c6-4c52-4b3b-a34f-a5930446f338",
   "metadata": {},
   "source": [
    "## Modifying the structure of a DataFrame\n",
    "\n",
    "DataFrames allow you to feely add or remove rows and columns. This is an important difference from NumPy ndarrays, which have a fixed size.\n",
    "\n",
    "Most operations that change the number of rows or columns do *not* alter the DataFrame in-place. Use assignment to create a new DataFrame with the requested change.\n",
    "\n",
    "For **removing duplicate rows**, see \"Filtering a DataFrame\", above. For **removing rows with missing values**, see \"Working with missing data\", below. \n",
    "\n",
    "**Add a column containing values from an ordered iterable.** Pandas allows you to append columns directly from base Python lists or tuples. The length of the data structure must be the same as the length of columns in the DataFrame. Make sure values are in the correct order (aligned) with rows in the DataFrame. In addition, make sure that the name of the new column does not duplicate an existing name; if there is a match in names, pandas will replace values in that column with values from the iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278e8503-5aa2-4b3b-ac2a-70d7207d15a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column from a list\n",
    "capitals =['Buenos Aires', 'Canberra', 'Vienna', 'Bridgetown', 'City of Brussels', 'Belmopan', 'Thimphu', 'Gaborone', 'Brasília', 'Phnom Penh', 'Ottawa', 'Santiago', 'Beijing', 'Bogotá', 'San José', 'Zagreb', 'Santo Domingo', 'Quito', 'Cairo', 'London', 'Helsinki', 'Paris', 'Berlin', 'Athens', 'Hong Kong', 'Budapest', 'Reykjavík', 'New Delhi', 'Jakarta', 'Tehran', 'Dublin', 'Rome', 'Kingston', 'Tokyo', 'Nairobi', 'Riga', 'Kuala Lumpur', 'Valletta', 'Mexico City', 'Rabat', 'Naypyidaw', 'Windhoek', 'Kathmandu', 'Amsterdam', 'Wellington', 'Oslo', 'Panama City', 'Port Moresby', 'Lima', 'Lisbon', 'San Juan', 'Doha', 'Bucharest', 'Edinburgh', 'Singapore', 'Ljubljana', 'Pretoria', 'Seoul', 'Madrid', 'Colombo', 'Stockholm', 'Bern', 'Taipei', 'Dodoma City', 'Bangkok', 'Ankara', 'Abu Dhabi', 'Washington', 'Hanoi', 'Charlotte Amalie']\n",
    "df['capital'] = capitals\n",
    "df.iloc[0:5, -5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a7fe3c-2bd8-42e2-91e8-ce6c452e3bca",
   "metadata": {},
   "source": [
    "**Add a column containing values computed from existing columns.** This operation is analogous to `mutate()` in dplyr. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46efd1fb-9cd1-416e-981d-7ea091b666cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column and populate with values computed with an expression\n",
    "df['fraction_endemic'] = df['species_endemic'] / df['species_total']\n",
    "df.iloc[0:5, -5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0be37a0-31fc-40e1-a54c-08793d7d7a0d",
   "metadata": {},
   "source": [
    "**Add a single row.** It is possible to use a Series or a base Python list or tuple to hold the new values. In each case, make sure the number of items matches the DataFrame and that items are in the correct order. Mismatch in overlall length or data type at any position will generate an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b17a75-429c-4ee7-b00b-a089a2bfe7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a row to an existing DataFrame\n",
    "new_row = ['Rohan', 'Middle Earth', 780, 0, 0, 'Gondorian', 2, 3, 352, 289, 0, 0, 0.32, 1399, 4512, 0.1, 3.2, 24.3, 0, 0, 0, 0, 0, 'Kingdom of Rohan', 'Kingdom of Rohan', 'RHN']\n",
    "df.loc[len(df)] = new_row\n",
    "df.iloc[-5:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35507f19-a60c-4424-8603-00febf4e9e00",
   "metadata": {},
   "source": [
    "**Delete rows or columns.** To delete duplicate rows, see \"Removing duplicates\" above; to delete rows with missing values, see \"Working with missing data\" below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98464b68-0353-450e-85be-33053db8ec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete a column based on its name\n",
    "#   to delete multiple columns, pass a list of names\n",
    "df = df.drop('country_iso', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb46c4f-0270-4f71-8d79-1d2109131513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete a row based on index\n",
    "#   to delete multiple rows, pass a list of values (can be discontinuous)\n",
    "df = df.drop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42816c0-838a-4501-afe8-dae4dd24d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rows based on condition\n",
    "#   filter without assignment first to test the condition!\n",
    "df = df[df['species_endemic'] >= 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76094ec-9423-4009-a2cd-1a55973ef4ed",
   "metadata": {},
   "source": [
    "**Swap rows and columns.** Use the `.T` or `.transpose()` method, similar to NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9251175-28a8-4454-b6ed-87e2dc855b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df.T\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d27994c-abe6-43c6-aca1-a2b5dc62f1c7",
   "metadata": {},
   "source": [
    "## Sorting a DataFrame\n",
    "\n",
    "Sorting refers to the *sequence* of rows. Sorting on one or more columns moves entires rows up or down. If multiple columns are specified, pandas sorts on the first, then uses the second to break any ties, and so forth. \n",
    "\n",
    "In most cases, the order of rows will change if you sort. This means that the integer index values will no longer be in numerical order. You can use `.loc[ ]` to locate rows by their original position or `.iloc[ ]` to locate them by their value.\n",
    "\n",
    "Note that sorting does not alter the original DataFrame; to capture the sorted DataFrame, assign to a new DataFrame. \n",
    "\n",
    "**Sorting based on values in a column or columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4267ffa1-0fef-4077-b29a-d554e1422f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort based on values in a single column\n",
    "df8 = df.sort_values('species_total')\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20d16f3-ffce-4221-993e-f59ca3aec6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort in descending order\n",
    "df.sort_values('species_total', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb0bcb1-3322-48b1-819f-efd9e797b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort based on values in a multiple columns\n",
    "df.sort_values(['bioregion_count','species_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d54a87-3a25-46cd-9b1f-82f0c9983070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify different sort orders when working with multiple columns\n",
    "df.sort_values(['bioregion_count','species_total'], ascending=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e3335f-af60-4802-aeec-303773da6dd3",
   "metadata": {},
   "source": [
    "**Sorting based on the index.** When using the default integer index, it is sometimes useful to reset values so that they are more intuitive (e.g., in ascending order following a sort). By default, resetting the index preserves the original index as a new data column and creates a new index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21309a35-3c62-48a1-8e8a-d50441d9e963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort based on the index\n",
    "df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70594f67-dc02-4421-aa5c-2f5e946fa1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort and then renumber the index\n",
    "df.sort_values('species_total').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639304ec-1477-4920-bc1d-933b0478bbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort and then renumber the index, discarding the previous index values\n",
    "df.sort_values('species_total').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ab62c1-c706-4b67-b1e2-c6ca35613f1e",
   "metadata": {},
   "source": [
    "## Working with missing data\n",
    "\n",
    "Pandas ignores missing values by default when computing summary statistics (similar to Dplyr in R). This can be convenient, but sometimes you want to eliminate rows with missing values in any or a particular column.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceb100f-bb15-457a-bdf6-b872ee800f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the .isna method to return a bool for every cell queried\n",
    "df[['species_total', 'biodiv_index']].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af4b517-74a1-4ed0-bcb0-dbe04b4de6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply .count to get a count of the missing values in a single column; does not work for multiple columns\n",
    "df[['biodiv_index']].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50db3a18-7d28-49f6-9dc4-ec278e650dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to drop rows with missing values in a specified column or columns\n",
    "df['biodiv_index'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d5a15a-adf4-403c-bc95-f740d34bf0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to replace missing values in a specified column or columns\n",
    "df[['biodiv_index']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeddbe0-5e3c-4cf7-a6f0-d846fd5f52ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
