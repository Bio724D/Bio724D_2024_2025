{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing from files\n",
    "\n",
    "The `open` function is the standard way to gain access to a file on your filesystem.  Files can be opened for reading only, writing, or both reading and writing.  By default files are opened in read only mode.  The primary argument to the `open` function is a string giving the path and name of the file you want to open:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### open function and file objects\n",
    "\n",
    "## You can download `covid-ref.fsa` from the course repository at \n",
    "##    https://github.com/Bio724D/Bio724D_2023_2024/tree/main/data\n",
    "#\n",
    "## This is a FASTA file of the Sars-Cov-2 reference genome\n",
    "## See: https://www.ncbi.nlm.nih.gov/nuccore/NC_045512\n",
    "##\n",
    "## the default is to open the file in read-only mode\n",
    "f = open(\"covid-ref.fsa\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to manipulate a file is simply to read all the information from it, return the data in the file as a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### reading everything from a file as a single string\n",
    "s = f.read()\n",
    "type(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've read what you need from the file it's good practice to close it (failing to close a file can lead to a memory leak in some contexts, but it's usually not a problem in an interactive environment like Jupyter notebooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternate way to read a file is within a `with` statement as illustrated below.  The advantage of the `with` statement is it insures the file is closed (i.e. you don't need to explicitly call the `close` method) at the end of the `with` block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"covid-ref.fsa\") as f:\n",
    "    s = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've read the file into a string we can apply all the standard string methods and operators to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30429"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s)  ## how many characters were in the file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'>NC_045512.2 Severe acute respiratory syndrome cor'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[:50]  ## first 50 chars in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CTTAGGAGAATGACAAAAAAAAAAAAAAAAAAAA\\nAAAAAAAAAAAAA\\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[-50:]  ## last 50 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a file by lines\n",
    "\n",
    "Sometimes it's more convenient or more efficient to get the information in the file in terms of lines.  The `readlines` method associated with file object read's all the lines at once in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## return a list of the lines in the file\n",
    "with open(\"./covid-ref.fsa\") as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'>NC_045512.2 Severe acute respiratory syndrome coronavirus 2 isolate Wuhan-Hu-1, complete genome\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the first line is a \"header\" line (see explanation of FASTA format below)\n",
    "# header lines start with a right bracket (>)\n",
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ATTAAAGGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAA\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subsequent lines are the actual sequence data\n",
    "lines[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the newline character (`\\n`) at the end of each line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a file one line at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `readlines` function illustrated above reads all the lines at once. That's works well if your file has a modest number of lines, but for a file with millions of lines (or very long  lines)  `readlines` might exhaust the memory of your computer.  One way to work around this is to process files line by line, reading only one line at a time.  This can be done with a for loop applied directly to the file object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[97, 71, 71, 71, 71, 71, 71, 71, 71, 71]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./covid-ref.fsa\") as f:\n",
    "    nchars = []  # create a list to hold characters counts per line\n",
    "    for line in f:\n",
    "        nchars.append(len(line)) \n",
    "\n",
    "nchars[:10]  # the first 10 counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For such a simple computation we'd typically use a list comprehension which you can think of as a compact version of a for loop (more on list comprehensions in a later class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[97, 71, 71, 71, 71, 71, 71, 71, 71, 71]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./covid-ref.fsa\") as f:\n",
    "    nchars = [len(line) for line in f]\n",
    "\n",
    "nchars[:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating through a file, filtering and concatenating lines\n",
    "\n",
    "Here we illustrate the process of iterating through the lines of a file, doing some simple filtering, and concatenating lines into a single string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the lines of \n",
    "seq = \"\"\n",
    "with open(\"./covid-ref.fsa\") as f:\n",
    "    for line in f:\n",
    "        if line[0] == \">\":  # if the line starts with right bracket\n",
    "            continue        # skip it (i.e. go to next iteration of for loop)\n",
    "        if len(line.strip()):    # if the line is not empty\n",
    "            seq += line.strip()  # add it to our seq string object\n",
    "            # NOTE: strip removes newlines and other whitespace at beginning/end of lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29903"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total length of COVID reference genome nucleotide sequence\n",
    "# does not include the header line which we filtered out in our for loop above\n",
    "len(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ATTAAAGGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAACTTTAAAATCTGTGTGGCTGTCACTC'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 100 characters in this sequence\n",
    "seq[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting codons  using string slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the string we're working with represents the Sars-Cov-2 genome, let's extract a subsequence of interest that represents the gene that encodes the Spike protein. Once we've done so we'll generate  codons from that subsequence and translate them to their corresponding amino acids.\n",
    "\n",
    "The spike protein coordinates from NCBI are given as: 21563..25384 but these are 1-indexed and inclusive of start/end coordinates. To extract the corresponding sequence from our Python string we need to convert these to 0-indexed coordinates and remember that Python indexing is up to but not including end index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spike protein coords from NCBI are given as: 21563..25384\n",
    "# Note conversion to 0-indexing and non-inclusive end index\n",
    "\n",
    "spike = seq[21562:25384]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3822"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of sequence we extracted\n",
    "len(spike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ATGTTTGTTT'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 10 nucleotides\n",
    "spike[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll extract the nucleotide triplets that represent the codons of the spike protein. This task is simple in this case because there are no introns to consider and the gene is encoded in the same strand orientation as the data is provided to us (not always the case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 6, 9, 12, 15, 18, 21, 24, 27]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of the start positions for each codon\n",
    "codon_starts = range(0, len(spike), 3)\n",
    "\n",
    "# we wrap this in a call to list() to see what it looks like\n",
    "# because range() returns an iterator\n",
    "list(codon_starts)[:10]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ATG', 'TTT', 'GTT', 'TTT', 'CTT', 'GTT', 'TTA', 'TTG', 'CCA', 'CTA']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract codon subsequences by indexing with codon starts and slicing three characters\n",
    "spike_codons = [spike[i:i+3] for i in codon_starts]\n",
    "spike_codons[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have codons we can explore setting up a dictionary to handle the translation. We're going to pull the genetic code information from the standard codon table given by NCBI (see below), which we'll arrange as a dictionary.  This dictionary maps from codons (the keys) to single-letter representations of amino acids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NCBI provides the described genetic codes here\n",
    "#   https://www.ncbi.nlm.nih.gov/Taxonomy/Utils/wprintgc.cgi#SG1\n",
    "# Below is the standard code\n",
    "# I did a simple cut and paste of the data from the NCBI website to create the strings below\n",
    "\n",
    "Base1  = \"TTTTTTTTTTTTTTTTCCCCCCCCCCCCCCCCAAAAAAAAAAAAAAAAGGGGGGGGGGGGGGGG\"\n",
    "Base2  = \"TTTTCCCCAAAAGGGGTTTTCCCCAAAAGGGGTTTTCCCCAAAAGGGGTTTTCCCCAAAAGGGG\"\n",
    "Base3  = \"TCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAGTCAG\"\n",
    "AAs    = \"FFLLSSSSYY**CC*WLLLLPPPPHHQQRRRRIIIMTTTTNNKKSSRRVVVVAAAADDEEGGGG\"\n",
    "\n",
    "## for example \"TTT\" (first column) translates to \"F\" (phenylalanine)\n",
    "## \"GGG\" (last column) translate to \"G\" (glycine), \"TAG\" to \"*\" (stop codon), etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can turn those strings into a dictionary as below\n",
    "\n",
    "codon2AA = dict() # empty dictionary\n",
    "\n",
    "for i in range(len(AAs)):    # like R's 1...leng\n",
    "    codon = Base1[i] + Base2[i] + Base3[i]  # create codon string\n",
    "    codon2AA[codon] = AAs[i]  # add entry mapping codong string to corresponding AA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('F', 'G', '*')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test our dict\n",
    "codon2AA[\"TTT\"], codon2AA[\"GGG\"], codon2AA[\"TAG\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having setup this dictionary mapping codons to corresponding amino acids we can \"translate\" the codons using simple dictionary lookup. Here we do this in a for loop, but a list comprehension would be more idiomatic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['M', 'F', 'V', 'F', 'L', 'V', 'L', 'L', 'P', 'L']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spike_AAs = []\n",
    "\n",
    "for codon in spike_codons:\n",
    "    spike_AAs.append(codon2AA[codon])\n",
    "\n",
    "spike_AAs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHAIHVSGTNGTKRFDNPVLPFNDGVYFASTEKSNI'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you have a list of strings and want to join them into a single string\n",
    "# the join() method is useful\n",
    "spike_protein = \"\".join(spike_AAs)  # what happens if you write \"!\".join(spike_AAs) instead?\n",
    "spike_protein[:100] # first 100 AAs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQYIKWPWYIWLGFIAGLIAIVMVTIMLCCMTSCCSCLKGCCSCGSCCKFDEDDSEPVLKGVKLHYT*'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spike_protein[-100:] # last 100 AAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The FASTA file format for sequence data\n",
    "\n",
    "The FASTA file format is the most commonly used file format used to represent nucleotide and protein sequence data.  Wikipedia has a good [overview of the FASTA format](https://en.wikipedia.org/wiki/FASTA_format).  \n",
    "\n",
    "Summary of FASTA format:\n",
    " \n",
    " * Each file can hold one or more sequence records\n",
    " \n",
    " * The beginning of each record is delimited by a line called a header, which has a `>` character at the beginning, followed by the name associated with that record (and an optional description). For example `>seq1 Involved in...` would indicate the beginning of a record with the name `seq1` and the description \"Involved in...\".\n",
    " \n",
    " * On or more sequence lines follow header lines.  These lines are usually wrapped to have length <=80 characters but this is not required.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a simple function that will parse a FASTA file, returning each record as an element in a Python dictionary with the first word in the header line of each record as the key. \n",
    "\n",
    "This implementation isn't particularly robust or optimal, but illustrates some key aspects of flow-control in Python and parsing non-tabular data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_FASTA(fname):\n",
    "    record_dict = {}\n",
    "    f = open(fname, 'r')\n",
    "    \n",
    "    recname = \"\"           # will hold names of records\n",
    "    seq = \"\"               # will hold seq strings\n",
    "    active_record = False  # indicates whether we are currently working on building a record\n",
    "    \n",
    "    for line in f.readlines():\n",
    "        \n",
    "        line = line.strip()  # strip any whitespace at beginning/end of line\n",
    "        \n",
    "        if line == \"\":       # empty line\n",
    "            continue         # go to next iteration of for loop\n",
    "            \n",
    " \n",
    "        if line[0] == \">\":                 # are we dealing with a new record?\n",
    "            if active_record:              # did we already have an active record?\n",
    "                record_dict[recname] = seq # if so, add to old active record to the dict so we can\n",
    "                                           # begin a new one \n",
    "            \n",
    "            recname = line[1:].split()[0]  # name of new record\n",
    "            seq = \"\"                       # reset variable holding the string\n",
    "            active_record = True           # set flag to indicate we now have an active record\n",
    "            continue                       # go to the next iteration of for loop, as there's nothing else to do\n",
    "        \n",
    "        seq += line\n",
    "        \n",
    "    if active_record:               # if we've exhausted all the lines, we might still have an active record\n",
    "        record_dict[recname] = seq  # if so, add it to the dict\n",
    "\n",
    "    f.close() # remember to close the file!\n",
    "\n",
    "    return record_dict\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test our `parse_FASTA` function download the [`Spike-protein-aligned.fasta`](https://github.com/Bio724D/Bio724D_2023_2024/tree/main/data/Spike-protein-aligned.fasta) file  to your computer and modify the paths below as necessary to load and parse the sequence records contained in that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "recs = parse_FASTA(\"./Spike-protein-aligned.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the type of object we got back\n",
    "type(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many records are there\n",
    "len(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KF367457.1',\n",
       " 'AY278488.2',\n",
       " 'NC_004718.3',\n",
       " 'MG772933.1',\n",
       " 'MT040333.1',\n",
       " 'MN908947.3',\n",
       " 'MN996532.1']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the keys of the dictionary of recrods\n",
    "list(recs.keys())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M-FVFLVL-LPLVSS----QCVNLTTRTQLPPAYTN--SSTRGVYYPDKVFRSSVLHLTQDLFLPFFSNVTWFHAIHVSG'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a specific record, and the first 80 AAs\n",
    "recs[\"MN996532.1\"][:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MKLLVLVF-ATLVSSYTIEKCLDFD\n",
      "M-FIFLLF-LTLTSGSDLDRCTTFD\n",
      "M-FIFLLF-LTLTSGSDLDRCTTFD\n",
      "M-LFFLFLQFALVNS----QCVNLT\n",
      "M-FVFLFV-LPLVSS----QCVNLT\n",
      "M-FVFLVL-LPLVSS----QCVNLT\n",
      "M-FVFLVL-LPLVSS----QCVNLT\n"
     ]
    }
   ],
   "source": [
    "# print the first 25 positions in the alignment for all the records\n",
    "for key in recs.keys():\n",
    "    print(recs[key][:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
